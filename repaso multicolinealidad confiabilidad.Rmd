---
title: "Untitled"
author: "Martin Salinas"
date: "2024-12-25"
output: html_document
---

# Repaso PEP 2

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regresión lineal

### Condiciones

1. La variable de respuesta debe ser continua y cuantitativa. Sin restricciones en su variabilidad
2. Los predictores deben ser cuantitativos o dicotomicos
3. Los predictores deben tener algun grado de variabilidad. No constantes
4. Cada predictor debe estar relacionado linealmente con la respuesta
5. La distribucion de los residuos debe de ser cercana a la normal centrada en cero
6. La variabilidad de los residuos debe ser aproximadamente 0 (homocedasticidad)
7. Los residuos deben ser independientes entre si
8. **NO** debe existir multicolinealidad
9. Las estimaciones de los coeficientes del modelo no debe estar alterados por unas pocas observaciones influyentes.

En caso de predictores categoricos no dicotomicos:
  1. Crear k-1 variables artificiales
  2. Para cada una de estas nuevas variables
    a) Escoger un nivel diferente de la variable original
    b) Asignar un 1 a todas las observaciones que tenga ese nivel y un 0 a las restantes
    
Ejemplo:

```{r}
library(dummy)

# Crear una matriz de datos.
persona <- 1:9
sexo <- c("F", "F", "M", "M", "M", "F", "M", "M", "F")
tipo <- c("B", "D", "A", "B", "A", "C", "D", "D", "D")
valor <- c(1.68, 2.79, 1.92, 2.26, 2.1, 2.63, 2.19, 3.62, 2.76)
datos <- data.frame(persona, sexo, tipo, valor)

# Crear variables artificiales.
datos.dummy <- dummy(datos)
datos.dummy[["sexo_F"]] <- NULL
datos.dummy[["tipo_A"]] <- NULL
datos.dummy[["valor"]] <- datos[["valor"]]

# Crear y mostrar el modelo de RLM usando variables indicadoras
modelo2 <- lm(valor ~ sexo_M + tipo_B + tipo_C + tipo_D, datos.dummy)
print(modelo2)

# Crear y mostrar el modelo de RLM dejando el trabajo a lm().
modelo <- lm(valor ~ sexo + tipo, datos)
print(modelo)

```

4. Saber si los predictores estan relacionados linealmente con la respuesta

```{r}
library(car)
# Verificar si los predictores estan relacionados linealmente con la respuesta
residualPlots(modelo)
```

5. Verificar si la distribucion de los residuos es cercana a la normal centrada en cero

```{r}
marginalModelPlots(modelo, sd = TRUE,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue", "red"))
```

6. Verificar si la variabilidad de los residuos es aproximadamente 0 (homocedasticidad)

```{r}
# Verificar si la variabilidad de los residuos es aproximadamente 0
ncvTest(modelo)
```
si el p-valor es menor a 0.05, entonces la variabilidad de los residuos no es aproximadamente 0

7. Verificar si los residuos son independientes entre si

```{r}
# Verificar si los residuos son independientes entre si
durbinWatsonTest(modelo)
```

8. Verificar si existe multicolinealidad

```{r}
# Verificar si existe multicolinealidad
vif(modelo)
```

de ser mayor a 10, entonces existe multicolinealidad y severa
si se encuentra entre 1 y 5 entonces existe multicolinealidad y moderada pero no es preocupante
si es igual a 1 entonces no existe multicolinealidad

9. Verificar si las estimaciones de los coeficientes del modelo no estan alterados por unas pocas observaciones influyentes

```{r}
# Verificar si las estimaciones de los coeficientes del modelo no estan alterados por unas pocas observaciones influyentes
influencePlot(modelo)
```

si hay observaciones mayor a 1 hay problemas o indefinidas peor

### Calidad predictiva

1. **R-cuadrado ajustado** (R^2 ajustado): Es una medida de la calidad del ajuste del modelo. Mide la proporción de la variabilidad de la variable de respuesta que es explicada por el modelo. Se calcula como:

```{r}
summary(modelo)$adj.r.squared
```

usando validacion cruzada

```{r}
library(caret)
library(dplyr)

opt <- options(warn = 1)

# Cargar los datos de mtcars.
datos <- mtcars |> filter(wt > 2 & wt < 5) |>
  mutate_at(c("cyl", "vs", "am", "gear", "carb"), as.factor)

# Ajustar y mostrar el modelo usando validación cruzada
# dejando uno fuera.
set.seed(111)
fmla <- formula("hp ~ mpg + cyl + disp + drat + qsec + vs + am + gear + carb")
entrenamiento <- train(fmla, data = datos, method = "lm",
                       trControl = trainControl(method = "LOOCV"))
modelo <- entrenamiento[["finalModel"]]

# Mostrar la fórmula y las predicciones del modelo.
cat("\n")
print(fmla)
cat("\n")

cat("Predicciones en cada pliegue:\n")
print(entrenamiento[["pred"]])

cat("Error estimado para el modelo:\n")
print(entrenamiento[["results"]])

cat("\n\n")
cat("Modelo con un predictor menos:\n")
cat("-----------------------------\n\n")

# Ajustar y mostrar el modelo usando validación cruzada
# dejando uno fuera sin la variable "carb".
set.seed(111)
fmla <- formula("hp ~ mpg + cyl + disp + drat + qsec + vs + am + gear")
entrenamiento <- train(fmla, data = datos, method = "lm",
                       trControl = trainControl(method = "LOOCV"))
modelo <- entrenamiento[["finalModel"]]

# Mostrar la fórmula y las predicciones del modelo modificado.
print(fmla)
cat("\n")
cat("Predicciones en cada pliegue:\n")
print(entrenamiento[["pred"]])

#Mostrar el resultado estimado para el modelo
cat("Error estimado para el modelo:\n")
print(entrenamiento[["results"]])

options(warn = opt[[1]])
```

Interpretación:
  - RMSE: Error cuadrático medio
  - Rsquared: R-cuadrado
  - MAE: Error absoluto medio
  

